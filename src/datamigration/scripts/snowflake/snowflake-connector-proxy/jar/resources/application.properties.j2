#Copyright 2023 Google LLC

#Licensed under the Apache License, Version 2.0 (the "License");
#you may not use this file except in compliance with the License.
#You may obtain a copy of the License at

#https://www.apache.org/licenses/LICENSE-2.0

#Unless required by applicable law or agreed to in writing, software
#distributed under the License is distributed on an "AS IS" BASIS,
#WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#See the License for the specific language governing permissions and
#limitations under the License.

#***************
#H2 Embedded database and JPA related property.
#Path where the data will be store, it will create file in this location.
spring.datasource.h2.url=jdbc:h2:file:~/h2db;AUTO_SERVER=TRUE
#Username for the database
spring.datasource.h2.username=test
#Password for the database
spring.datasource.h2.password=test
spring.datasource.h2.driver-class-name=org.h2.Driver
spring.jpa.database-platform=org.hibernate.dialect.H2Dialect
spring.h2.console.enabled=true
# It will show the sql generated by JPA in the log.
spring.jpa.show-sql=false
spring.jpa.hibernate.ddl-auto=update
#***************
#Snowflake connection related property.
# JDBC url to connect to Snowflake.
jdbc.url={{ jdbc_url }}
#database.name=TEST_DATABASE
#schema.name=public
# Authenticator type which OAuth-based authentication.
authenticator.type=oauth
#Snowflake account URL
snowflake.account.url={{ account_url }}
#***************
#application related property
# Path where the query to table mapping JSON will be stored. This will be loaded during application startup and override the value corresponding to the tablename at runtime.
# /Users/sumitba/Documents/git/snowflake-to-bq-connector/src/main/resources
snowflake.table.query.mapping.path={{ query_mapping_file }}
# Path of json which holds the request body for the rest request which application uses. This will be loaded during application startup.
snowflake.request.body.json.path={{ request_body_file }}

# Maximum number of attempts, to check the status of the request which is initiated for exporting data from Snowflake to GCS. If request is not completed with in these many attempt,
# application will stop polling and corresponding execution will be considered completed without data export. It may be possible the data will get exported completely from Snowflake,
# because that request does not get stopped
snowflake.rest.api.max.attempt=10
# This is related to above property. This will be the delay between the attempts which waiting for rest API request to be completed. Duration is in seconds.
snowflake.rest.api.poll.duration=20
# Service account path which will be used by BigQuery and GCS client. It should have required permissions.
service.account.file.path=
# Initial startup time for a Scheduler which will refresh the access token. value given is in MilliSeconds
token.refresh.scheduler.initial.delay=300000
# Fixe rate time for a Scheduler which will be used to refresh the token, before updating this interval check the validity in Snowflake. Currently, its 10 min. Below value is in MilliSeconds
token.refresh.scheduler.fixed.rate=600000
# Time interval to wait before checking the status or migration(ddl translation) request completion status. Depending upon the complexity and number of ddls it should be increased or decreased.
migration.workflow.duration=120000
# Property to define the max pool size of thread executor which will be used by running the jobs parallel via Async annotation
custom.thread.executor.max.pool.size=10
# Enable below property to print DEBUG level logs. This can also be supplied during application startup.
#logging.level.org.springframework=DEBUG